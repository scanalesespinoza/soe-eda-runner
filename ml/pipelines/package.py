"""Standardise and publish model artefacts to the model registry (S3).

The packaging command consolidates the artefacts generated by ``train.py`` into
the canonical layout used across the project::

    s3://<bucket>/<dataset>/<model>/<timestamp>/
        model.onnx | model.pkl
        metrics.json
        model-card.yaml
        model-metadata.json
        sha.txt

The script works both with a plain filesystem destination (useful for tests) or
with an S3 bucket.  Uploading to S3 requires the usual ``S3_*`` environment
variables understood by the rest of the repository (``S3_ENDPOINT``,
``S3_ACCESS_KEY``, ``S3_SECRET_KEY`` and optionally ``S3_REGION``/``AWS_REGION``).
"""

from __future__ import annotations

import argparse
import hashlib
import json
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, Iterable, Tuple
from urllib.parse import urlparse


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Package model artefacts")
    parser.add_argument("--run-dir", required=True, help="Directory produced by train.py")
    parser.add_argument("--dataset", required=True, help="Dataset identifier")
    parser.add_argument("--model-name", required=True, help="Logical model name")
    parser.add_argument(
        "--s3-base",
        default="s3://models",
        help="Base URI for the model registry (use file:// or path for local storage)",
    )
    parser.add_argument("--timestamp", help="Override timestamp (YYYYmmddHHMMSS)")
    parser.add_argument("--dest-dir", help="Optional local destination before upload")
    parser.add_argument(
        "--skip-upload",
        action="store_true",
        help="Do not attempt to upload to S3 (useful for dry runs)",
    )
    return parser.parse_args()


def discover_artefacts(run_dir: Path) -> Dict[str, Path]:
    expected = {
        "metrics": "metrics.json",
        "model_card": "model-card.yaml",
        "metadata": "model-metadata.json",
    }
    artefacts = {}
    for key, filename in expected.items():
        path = run_dir / filename
        if not path.exists():
            raise FileNotFoundError(f"Expected artefact missing: {path}")
        artefacts[key] = path

    model_candidates = ["model.onnx", "model.pkl"]
    for candidate in model_candidates:
        path = run_dir / candidate
        if path.exists():
            artefacts["model"] = path
            artefacts["model_format"] = candidate.split(".")[-1]
            break
    else:  # pragma: no cover - defensive
        raise FileNotFoundError("No model artefact found (expected model.onnx or model.pkl)")

    return artefacts


def ensure_destination(path: Path) -> Path:
    path.mkdir(parents=True, exist_ok=True)
    return path


def copy_artefacts(artefacts: Dict[str, Path], dest: Path) -> Dict[str, Path]:
    copied: Dict[str, Path] = {}
    for key, src in artefacts.items():
        if key == "model_format":
            continue
        target_name = src.name
        target = dest / target_name
        shutil.copy2(src, target)
        copied[key] = target
    return copied


def write_sha(model_path: Path) -> Path:
    h = hashlib.sha256()
    with open(model_path, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    sha_path = model_path.parent / "sha.txt"
    with open(sha_path, "w", encoding="utf-8") as f:
        f.write(h.hexdigest())
    return sha_path


def build_s3_prefix(args: argparse.Namespace, timestamp: str) -> Tuple[str, str]:
    parsed = urlparse(args.s3_base)
    if parsed.scheme != "s3":
        raise ValueError("s3-base must be an s3:// URI when uploading")
    bucket = parsed.netloc
    base_prefix = parsed.path.lstrip("/")
    prefix = "/".join(filter(None, [base_prefix, args.dataset, args.model_name, timestamp]))
    return bucket, prefix


def upload_files(files: Iterable[Path], bucket: str, prefix: str) -> None:
    try:
        import boto3
        from botocore.exceptions import BotoCoreError, ClientError
    except Exception as exc:  # pragma: no cover - boto3 not available in tests
        raise RuntimeError("boto3 is required to upload artefacts to S3") from exc

    session = boto3.session.Session(
        aws_access_key_id=os.getenv("S3_ACCESS_KEY"),
        aws_secret_access_key=os.getenv("S3_SECRET_KEY"),
        region_name=os.getenv("AWS_REGION", os.getenv("S3_REGION", "us-east-1")),
    )
    client = session.client("s3", endpoint_url=os.getenv("S3_ENDPOINT"))

    for path in files:
        key = f"{prefix}/{path.name}"
        try:
            client.upload_file(str(path), bucket, key)
            print(f"[package] Uploaded {path.name} -> s3://{bucket}/{key}")
        except (BotoCoreError, ClientError) as exc:  # pragma: no cover - network
            raise RuntimeError(f"Failed to upload {path} to s3://{bucket}/{key}") from exc


def main() -> None:
    args = parse_args()
    run_dir = Path(args.run_dir)
    timestamp = args.timestamp or datetime.utcnow().strftime("%Y%m%d%H%M%S")

    artefacts = discover_artefacts(run_dir)

    dest_dir = Path(args.dest_dir) if args.dest_dir else run_dir / "package"
    dest_dir = ensure_destination(dest_dir)

    copied = copy_artefacts(artefacts, dest_dir)
    sha_path = write_sha(copied["model"])
    copied["sha"] = sha_path

    manifest_path = dest_dir / "manifest.json"
    manifest = {
        "dataset": args.dataset,
        "model": args.model_name,
        "timestamp": timestamp,
        "artefacts": {k: str(v.name) for k, v in copied.items()},
        "model_format": artefacts.get("model_format", "onnx"),
    }
    with open(manifest_path, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2)

    files_to_publish = list(copied.values()) + [manifest_path]

    if not args.skip_upload and args.s3_base.startswith("s3://"):
        bucket, prefix = build_s3_prefix(args, timestamp)
        upload_files(files_to_publish, bucket, prefix)
        print(f"[package] Artefacts available under s3://{bucket}/{prefix}/")
    else:
        print(f"[package] Artefacts staged in {dest_dir}")


if __name__ == "__main__":
    main()

